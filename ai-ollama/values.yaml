ollama:
  runtimeClassName: "nvidia"  # to use gpu
  ollama:
    gpu:
      # enable gpu if your k8s containerd/docker has gpu support
      enabled: true
    models:
      pull:
        - deepseek-r1:1.5b
        - deepseek-r1:7b
        - deepseek-r1:8b
        - deepseek-r1:14b
        - deepseek-r1:32b
        #- deepseek-v3
        - nezahatkorkmaz/deepseek-v3:latest
        - ishumilin/deepseek-r1-coder-tools:14b
        - MFDoom/deepseek-r1-tool-calling:14b
        #- llama3.2:3b
        #- llama3.1
        #- llava  # for image recognition
        #- codellama:7b
        #- qwen2.5-coder:7b
        ##- mistral
      run:
        - deepseek-r1:1.5b
        - deepseek-r1:7b
        - deepseek-r1:8b
        - deepseek-r1:14b
        - deepseek-r1:32b
        #- deepseek-v3
        - nezahatkorkmaz/deepseek-v3:latest
        - ishumilin/deepseek-r1-coder-tools:14b
        - MFDoom/deepseek-r1-tool-calling:14b
        #- llama3.2:3b
        #- llama3.1
        #- llava  # for image recognition
        #- codellama:7b
        #- qwen2.5-coder:7b
        ##- mistral
  ingress:
    enabled: true
    ingressClassName: traefik
    hosts:
    - host: ollama-api.local
      paths:
        - path: /
          pathType: Prefix
  extraEnv:
    - name: OLLAMA_ORIGINS
      value: "*"
