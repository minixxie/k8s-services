apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-vllm
  namespace: ai-vllm
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ai-vllm
  template:
    metadata:
      annotations:
      labels:
        app: ai-vllm
    spec:
      runtimeClassName: nvidia
      containers:
        - name: main
          #image: vllm/vllm-openai:v0.7.3
          image: minixxie/vllm:0.0.1
          imagePullPolicy: IfNotPresent
          #command: ["vllm", "serve", "--port", "80", "Qwen/Qwen2.5-Coder-7B-Instruct"]
          #command: ["vllm", "serve", "--port", "80", "Qwen/Qwen2.5-Coder-1.5B-Instruct"]
          #command: ["vllm", "serve", "--port", "80", "Qwen/Qwen2.5-Coder-1.5B"]
          #command: ["vllm", "serve", "--port", "80", "codellama/CodeLlama-7b-hf"]
          #command: ["vllm", "serve", "--port", "80", "/datascience-models/DeepSeek-V2-Lite", "--trust-remote-code"]
          command: ["vllm", "serve", "--port", "80", "/datascience-models/DeepSeek-R1-Distill-Qwen-1.5B", "--gpu-memory-utilization", "0.95", "--trust-remote-code"]
          #command: ["sleep", "24h"]
          resources:
            limits:
              nvidia.com/gpu: 1 # requesting 1 GPU
          ports:
            - name: http
              containerPort: 80  # HTTP port
          readinessProbe:
            httpGet:
              path: /health
              port: 80
            initialDelaySeconds: 10
            periodSeconds: 30
          env:
            - name: NVIDIA_VISIBLE_DEVICES
              value: "all"
            - name: NVIDIA_DRIVER_CAPABILITIES
              value: "compute,utility"
            - name: PYTORCH_CUDA_ALLOC_CONF
              value: "expandable_segments:True"
            - name: TORCH_CUDA_ARCH_LIST
              value: "8.6"  # Adjust based on your GPU architecture
          volumeMounts:
            - name: datascience-models
              subPath: DeepSeek-V2-Lite
              mountPath: /datascience-models/DeepSeek-V2-Lite
              readOnly: true
            - name: datascience-models
              subPath: DeepSeek-R1-Distill-Qwen-1.5B
              mountPath: /datascience-models/DeepSeek-R1-Distill-Qwen-1.5B
              readOnly: true
      volumes:
        - name: datascience-models
          persistentVolumeClaim:
            claimName: datascience-models
